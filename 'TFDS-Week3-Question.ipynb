{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RoPuCbDtBlYK"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from os import getcwd\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOI6Dk_oJQEK"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_layer = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_tensor=input_layer,\n",
    "                                                   weights='imagenet',\n",
    "                                                   include_top=False)\n",
    "    base_model.trainable = False\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=x)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPjns6UfCCSn"
   },
   "outputs": [],
   "source": [
    "dataset_name = 'cats_vs_dogs'\n",
    "filePath = f\"{getcwd()}/../tmp2\"\n",
    "dataset, info = tfds.load(name=dataset_name, split=tfds.Split.TRAIN, with_info=True, data_dir=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hN3P7OWKQLG2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_datasets.core.utils.version.Version at 0x7fd4c45e06a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(info.version)\n",
    "info.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjDp0wOBJdLR"
   },
   "source": [
    "# Naively training with tf.data\n",
    "\n",
    "Let us run through the code in a normal scenario. We will not use any of the new concepts of parallelization we have learnt in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3Q7Etb8ENRG"
   },
   "outputs": [],
   "source": [
    "def preprocess(features):\n",
    "    image = features['image']\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = image / 255.0\n",
    "    return image, features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQCfvf4WENg2"
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset.map(preprocess).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jyjiJd8Cvwc"
   },
   "source": [
    "```python\n",
    "model = create_model()\n",
    "model.fit(train_dataset, epochs=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5fzrFnXLEJW"
   },
   "source": [
    "# Exercise\n",
    "\n",
    "This exercise is about parallelizing various stages of Extract, Transform and Load processes. In this exercise, you will be tasked with following tasks:   \n",
    "\n",
    "1.   Parallelize extraction of stored TFRecords of cats_vs_dogs dataset using interleave operation.\n",
    "2.   Parallelize transformation during preprocessing of raw dataset using map operation.\n",
    "3.   Cache the processed dataset in memory using cache operation for faster retrieval.\n",
    "4.   Parallelize the loading of cached dataset during training cycle using prefetch operation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9Tqn9gALFaE"
   },
   "outputs": [],
   "source": [
    "file_pattern = f'{getcwd()}/../tmp2/{dataset_name}/{info.version}/{dataset_name}-train.tfrecord*'\n",
    "files = tf.data.Dataset.list_files(file_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqvYsWmVS9EW"
   },
   "source": [
    "## Parallelize Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zYCJMSoSHhd"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Parallelize the extraction of the stored TFRecords of\n",
    "# the cats_vs_dogs dataset by using the interleave operation with\n",
    "# cycle_length = 4 and the number of parallel calls set to tf.data.experimental.AUTOTUNE.\n",
    "train_dataset = files.interleave(tf.data.TFRecordDataset, \n",
    "                               cycle_length=4,\n",
    "                               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    \n",
    "    # Create the feature description dictionary\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature((), tf.string, \"\"),\n",
    "        'label': tf.io.FixedLenFeature((), tf.int64, -1),\n",
    "    }\n",
    "    # Parse the serialized_example and decode the image\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "    image = tf.io.decode_jpeg(example['image'], channels=3)\n",
    "    \n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    # Normalize the pixels in the image\n",
    "    image = image/255.\n",
    "    \n",
    "    # Resize the image to (224, 224) using tf.image.resize\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    \n",
    "    return image, example['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OiL5S0GdTKPK"
   },
   "source": [
    "## Parallelize Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRFO7n7odLTk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Get the number of CPU cores. \n",
    "cores = cores = multiprocessing.cpu_count()\n",
    "\n",
    "print(cores)\n",
    "\n",
    "# Apply the map transformation with number of parallel calls set to number of cores\n",
    "train_dataset = train_dataset.map(read_tfrecord,num_parallel_calls=cores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43XLYAvGTsew"
   },
   "source": [
    "## Cache the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0zWUJ3gTuRx"
   },
   "outputs": [],
   "source": [
    "# Cache the dataset in-memory\n",
    "train_dataset = dataset.cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KhpFlwM8TTxO"
   },
   "source": [
    "## Parallelize Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FdZ-aTECSE2a"
   },
   "outputs": [],
   "source": [
    "# Shuffle and batch the dataset\n",
    "train_dataset = train_dataset.shuffle(1024).batch(32)\n",
    "# Parallelize the loading by prefetching the dataset and setting buffer size to AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSMpkNrbLFoa"
   },
   "source": [
    "```python\n",
    "model = create_model()\n",
    "model.fit(train_dataset, epochs=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uJPiA98oPfrg"
   },
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above.\n",
    "# Once that is complete, please run the following two cells to save your work and close the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Shutdown and close the notebook -->\n",
    "window.onbeforeunload = null\n",
    "window.close();\n",
    "IPython.notebook.session.delete();"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Module3 Exercise-Question.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "coursera": {
   "course_slug": "data-pipelines-tensorflow",
   "graded_item_id": "PPCTl",
   "launcher_item_id": "84r9D"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
